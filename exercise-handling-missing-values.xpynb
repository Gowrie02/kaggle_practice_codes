from learntools.core import binder
binder.bind(globals())
from learntools.data_cleaning.ex1 import *

# modules we'll use
import pandas as pd
import numpy as np

# read in all our data
sf_permits = pd.read_csv("../input/building-permit-applications-data/Building_Permits.csv")

# set seed for reproducibility
np.random.seed(0) 

sf_permits.head()

#How many missing data points do we have?

missing_values=sf_permits.isnull().sum()

total_cells = np.product(sf_permits.shape)
total_missing = missing_values.sum()


percent_missing = (total_missing/total_cells) * 100

#Drop missing values: rows
sf_permits.dropna()



sf_permits_with_na_dropped = sf_permits.dropna(axis=1)

original_dataset = sf_permits.shape[1]
na_dropped = sf_permits_with_na_dropped.shape[1]

dropped_columns = original_dataset - na_dropped

#Fill in missing values automatically
sf_permits_with_na_imputed =sf_permits.fillna(method='bfill',axis=0).fillna(0)

